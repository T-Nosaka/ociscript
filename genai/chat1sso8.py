import streamlit as st
import base64
import oci
from oci.generative_ai import GenerativeAiClient
from oci.generative_ai_inference import GenerativeAiInferenceClient
from oci.generative_ai_inference.models import (
    AudioContent,
    AudioUrl,
    ImageContent,
    ImageUrl,
    VideoContent,
    VideoUrl,
    TextContent,
    Message,
    ChatDetails,
    CohereChatRequest,
    GenericChatRequest,
    OnDemandServingMode
)
import uuid
import datetime
import time
import pytz
import hashlib
import json

from chatdb import chatdb

# ãƒ†ãƒ¼ãƒã®å–å¾—
theme = "dark" if st.config.get_option("theme.base") == "dark" else "light"

# ãƒ¢ãƒã‚¤ãƒ«è¡¨ç¤ºã®å•é¡Œã‚’ä¿®æ­£
# ãƒ†ãƒ¼ãƒã«å¿œã˜ãŸCSSã‚’é©ç”¨
st.markdown(f"""
<style>
@media (max-width: 800px) {{
    .stChatInput {{
        position: fixed;
        bottom: 0;
        left: 0;
        width: 100%;
        padding: 10px;
        z-index: 1000;
        transition: background-color 0.3s ease;
    }}
    .stChatInput textarea {{
        width: 100%;
        box-sizing: border-box;
    }}

    /* Lightãƒ¢ãƒ¼ãƒ‰ã®ã‚¹ã‚¿ã‚¤ãƒ« */
    .{theme}-mode .stChatInput {{
        background-color: #ffffff;
        border-top: 1px solid #ccc;
        box-shadow: 0 -2px 5px rgba(0, 0, 0, 0.1);
    }}

    /* Darkãƒ¢ãƒ¼ãƒ‰ã®ã‚¹ã‚¿ã‚¤ãƒ« */
    .dark-mode .stChatInput {{
        background-color: #1e1e1e;
        border-top: 1px solid #444;
        box-shadow: 0 -2px 5px rgba(0, 0, 0, 0.5);
    }}
    .dark-mode .stChatInput textarea {{
        color: #ffffff;
        background-color: #1e1e1e;
    }}
}}
</style>
""", unsafe_allow_html=True)

# OCIèªè¨¼æƒ…å ±
config = oci.config.from_file(st.secrets["oci"]["config_path"], st.secrets["oci"]["config_name"])
COMPARTMENT_ID = st.secrets["oci"]["compartment"]

#ãƒ¡ãƒ‡ã‚£ã‚¢çŠ¶æ³
CANMOVIE = ["google.gemini-2.5-flash","google.gemini-2.5-pro","google.gemini-2.5-flash-lite"]
CANAUDIO = ["google.gemini-2.5-flash","google.gemini-2.5-pro","google.gemini-2.5-flash-lite"]
CANIMAGE = ["google.gemini-2.5-flash","google.gemini-2.5-pro","google.gemini-2.5-flash-lite",
            "meta.llama-4-maverick-17b-128e-instruct-fp8","meta.llama-4-scout-17b-16e-instruct",
            "xai.grok-4-fast-non-reasoning","xai.grok-4-fast-reasoning","xai.grok-4"]

DEBUG_MODE=False

# Googleèªè¨¼
LOGINBTN = "Googleã§ãƒ­ã‚°ã‚¤ãƒ³"
AUTHSECTION = "google"
# èªè¨¼IDè­˜åˆ¥å­
def AUTHID(user) :
    return user.get("sub")
# è¨±å¯ç¢ºèªã™ã‚‹
def isContain(oid) :
    return True


# ãƒãƒ£ãƒƒãƒˆDB
db = chatdb(config,COMPARTMENT_ID)

# å‹•ç”»å…¥åŠ›æ©Ÿèƒ½æœ‰ç„¡
def hasMovieFunction(model:oci.generative_ai.models.Model):
    if model.display_name in CANMOVIE:
        return True
    return False

# ç”»åƒå…¥åŠ›æ©Ÿèƒ½æœ‰ç„¡
def hasImageFunction(model:oci.generative_ai.models.Model):
    if model.display_name in CANIMAGE:
        return True
    return False

# éŸ³å£°å…¥åŠ›æ©Ÿèƒ½æœ‰ç„¡
def hasAudioFunction(model:oci.generative_ai.models.Model):
    if model.display_name in CANAUDIO:
        return True
    return False

# æœ€å¤§ãƒˆãƒ¼ã‚¯ãƒ³æ•°
def getMaxToken( model:oci.generative_ai.models.Model):
    if model.display_name in ["google.gemini-2.5-flash","google.gemini-2.5-pro","google.gemini-2.5-flash-lite"]:
        return 65536
    if model.display_name in ["xai.grok-3","xai.grok-3-fast","xai.grok-3-mini","xai.grok-3-mini-fast"]:
        return 16000
    if model.display_name in ["xai.grok-4","xai.grok-code-fast-1"]:
        return 131000
    if model.display_name in ["xai.grok-4-fast-non-reasoning","xai.grok-4-fast-reasoning"]:
        return 256000
    return 4000


# Generative AI ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã®åˆæœŸåŒ–
DEFAULT_MODEL = "google.gemini-2.5-flash"
client = GenerativeAiInferenceClient(config=config)
generative_ai_client = GenerativeAiClient(config)

# æ—¥æœ¬ã‚¿ã‚¤ãƒ ã‚¾ãƒ¼ãƒ³
jst_timezone = pytz.timezone('Asia/Tokyo')

#æ—¥æ™‚å¤‰æ›->JST
def parseDateTime( tm ) :
    return datetime.datetime.fromisoformat(tm.replace('Z', '+00:00')).astimezone(jst_timezone)

# ã‚»ãƒƒã‚·ãƒ§ãƒ³IDç”Ÿæˆ
def generate_unique_session_id() -> str:
    return hashlib.md5(str(uuid.uuid4()).encode('utf-8')).hexdigest()[:12]

# ã‚¨ã‚­ã‚¹ãƒãƒ¼ãƒˆé–¢æ•°ç¾¤
def export_as_text(chat_history, session_id, title):
    """ãƒ†ã‚­ã‚¹ãƒˆå½¢å¼ã§ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ"""
    content = f"ãƒãƒ£ãƒƒãƒˆå±¥æ­´: {title}\nã‚»ãƒƒã‚·ãƒ§ãƒ³ID: {session_id}\n"
    content += f"ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆæ—¥æ™‚: {datetime.datetime.now(jst_timezone).strftime('%Y-%m-%d %H:%M:%S')}\n"
    content += "=" * 50 + "\n\n"
    
    for msg in chat_history:
        timestamp = parseDateTime(msg.get('timestamp', datetime.datetime.now().isoformat())) if 'timestamp' in msg else ""
        role_display = "ãƒ¦ãƒ¼ã‚¶ãƒ¼" if msg['role'].upper() == "USER" else "ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆ"
        content += f"[{timestamp.strftime('%Y-%m-%d %H:%M:%S') if timestamp else 'N/A'}] {role_display}:\n"
        content += f"{msg['message']}\n\n"
    
    return content

def export_as_json(chat_history, session_id, title):
    """JSONå½¢å¼ã§ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ"""
    export_data = {
        "session_id": session_id,
        "title": title,
        "export_datetime": datetime.datetime.now(jst_timezone).isoformat(),
        "messages": []
    }
    
    for msg in chat_history:
        timestamp = parseDateTime(msg.get('timestamp', datetime.datetime.now().isoformat())) if 'timestamp' in msg else None
        export_data["messages"].append({
            "role": msg['role'],
            "message": msg['message'],
            "timestamp": timestamp.isoformat() if timestamp else None
        })
    
    return json.dumps(export_data, ensure_ascii=False, indent=2)

def export_as_markdown(chat_history, session_id, title):
    """Markdownå½¢å¼ã§ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ"""
    content = f"# {title}\n\n"
    content += f"**ã‚»ãƒƒã‚·ãƒ§ãƒ³ID:** {session_id}  \n"
    content += f"**ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆæ—¥æ™‚:** {datetime.datetime.now(jst_timezone).strftime('%Y-%m-%d %H:%M:%S')}  \n\n"
    content += "---\n\n"
    
    for i, msg in enumerate(chat_history, 1):
        timestamp = parseDateTime(msg.get('timestamp', datetime.datetime.now().isoformat())) if 'timestamp' in msg else ""
        role_display = "ğŸ§‘ ãƒ¦ãƒ¼ã‚¶ãƒ¼" if msg['role'].upper() == "USER" else "ğŸ¤– ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆ"
        
        content += f"## {i}. {role_display}\n\n"
        if timestamp:
            content += f"*{timestamp.strftime('%Y-%m-%d %H:%M:%S')}*\n\n"
        content += f"{msg['message']}\n\n"
        content += "---\n\n"
    
    return content

def import_from_json(json_content, oid):
    """JSONå½¢å¼ã‹ã‚‰ãƒãƒ£ãƒƒãƒˆå±¥æ­´ã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆ"""
    try:
        import_data = json.loads(json_content)
        
        # å¿…é ˆãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã®æ¤œè¨¼
        if not all(key in import_data for key in ["session_id", "title", "messages"]):
            return False, "ä¸æ­£ãªJSONãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã§ã™ã€‚å¿…é ˆãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ãŒä¸è¶³ã—ã¦ã„ã¾ã™ã€‚"
        
        # æ–°ã—ã„ã‚»ãƒƒã‚·ãƒ§ãƒ³IDã‚’ç”Ÿæˆï¼ˆé‡è¤‡ã‚’é¿ã‘ã‚‹ãŸã‚ï¼‰
        new_session_id = generate_unique_session_id()
        title = import_data.get("title", "ã‚¤ãƒ³ãƒãƒ¼ãƒˆã•ã‚ŒãŸãƒãƒ£ãƒƒãƒˆ")
        
        # ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã®æ¤œè¨¼ã¨ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
        imported_count = 0
        for msg in import_data["messages"]:
            if "role" in msg and "message" in msg:
                role = msg["role"].upper()
                if role in ["USER", "CHATBOT", "ASSISTANT"]:
                    # ASSISTANTã‚’CHATBOTã«å¤‰æ›
                    if role == "ASSISTANT":
                        role = "CHATBOT"
                    
                    # ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã®ä¿å­˜
                    db.save_chat_message(oid, new_session_id, role, msg["message"], title)
                    imported_count += 1

                    print(f"ã‚¤ãƒ³ãƒãƒ¼ãƒˆ: ã‚»ãƒƒã‚·ãƒ§ãƒ³ID={new_session_id}, ãƒ­ãƒ¼ãƒ«={role}, ã‚«ã‚¦ãƒ³ãƒˆ={imported_count}")
        
        if imported_count > 0:
            return True, f"æ­£å¸¸ã«ã‚¤ãƒ³ãƒãƒ¼ãƒˆã•ã‚Œã¾ã—ãŸã€‚{imported_count}ä»¶ã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆã—ã¾ã—ãŸã€‚"
        else:
            return False, "æœ‰åŠ¹ãªãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚"
            
    except json.JSONDecodeError:
        return False, "JSONå½¢å¼ãŒä¸æ­£ã§ã™ã€‚"
    except Exception as e:
        return False, f"ã‚¤ãƒ³ãƒãƒ¼ãƒˆä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}"

def validate_json_format(json_content):
    """JSONãƒ•ã‚¡ã‚¤ãƒ«ã®å½¢å¼ã‚’äº‹å‰æ¤œè¨¼"""
    try:
        data = json.loads(json_content)
        
        # åŸºæœ¬æ§‹é€ ã®ç¢ºèª
        required_fields = ["session_id", "title", "messages"]
        missing_fields = [field for field in required_fields if field not in data]
        
        if missing_fields:
            return False, f"å¿…é ˆãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ãŒä¸è¶³ã—ã¦ã„ã¾ã™: {', '.join(missing_fields)}"
        
        # ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã®æ§‹é€ ç¢ºèª
        if not isinstance(data["messages"], list):
            return False, "messages ã¯é…åˆ—ã§ã‚ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™ã€‚"
        
        valid_messages = 0
        for i, msg in enumerate(data["messages"]):
            if isinstance(msg, dict) and "role" in msg and "message" in msg:
                if msg["role"].upper() in ["USER", "CHATBOT", "ASSISTANT"]:
                    valid_messages += 1
        
        if valid_messages == 0:
            return False, "æœ‰åŠ¹ãªãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚"
        
        return True, f"æœ‰åŠ¹ãªJSONãƒ•ã‚¡ã‚¤ãƒ«ã§ã™ã€‚{valid_messages}ä»¶ã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ãŒå«ã¾ã‚Œã¦ã„ã¾ã™ã€‚"
        
    except json.JSONDecodeError:
        return False, "JSONå½¢å¼ãŒä¸æ­£ã§ã™ã€‚"
    except Exception as e:
        return False, f"æ¤œè¨¼ã‚¨ãƒ©ãƒ¼: {str(e)}"


#ãƒ¢ãƒ‡ãƒ«ä¸€è¦§
available_models = []
ret:oci.response.Response = generative_ai_client.list_models( compartment_id=COMPARTMENT_ID)
models:oci.generative_ai.models.ModelCollection = ret.data
model:oci.generative_ai.models.Model
for model in models.items:
    if model.time_on_demand_retired is None:
        if "FINE_TUNE" not in model.capabilities :
            if "CHAT" in model.capabilities :
                available_models.append(model)
#                print(f"{model.display_name}")

#ã‚¿ã‚¤ãƒˆãƒ«
st.title("OCI AI Chat")

oid=""
if DEBUG_MODE:
    oid = "aaaaaaaaa"
else:
    if not st.user.is_logged_in:
        st.title("ãƒ­ã‚°ã‚¤ãƒ³ã—ã¦ãã ã•ã„")
        if st.button(LOGINBTN):
            st.login(AUTHSECTION)
            st.stop()
    else:
        oid = AUTHID(st.user)

if 'nosql_table_checked' not in st.session_state:
    db.createtable()
    st.session_state.nosql_table_checked = True

if 'current_chat_session_id' not in st.session_state:
    st.session_state.current_chat_session_id = None

if 'messages_loaded_for_session' not in st.session_state:
    st.session_state.messages_loaded_for_session = None

# ãƒ­ã‚°ã‚¢ã‚¦ãƒˆãƒœã‚¿ãƒ³
if st.button("ãƒ­ã‚°ã‚¢ã‚¦ãƒˆ"):
    st.logout()

# åˆ©ç”¨å¯èƒ½æ¨©é™ãƒã‚§ãƒƒã‚¯
if( isContain(oid) == False ) :
    st.write("è¨±å¯ã•ã‚Œã¦ã„ã¾ã›ã‚“")
else :
    if DEBUG_MODE:
        None
    else:
        st.sidebar.header(f"Login: {st.user.name}")
    selected_model = st.sidebar.selectbox(
        "ä½¿ç”¨ã™ã‚‹ãƒ¢ãƒ‡ãƒ«ã‚’é¸æŠ",
        available_models,
        format_func = lambda model: f"{model.display_name}",
        index= [i for i, model in enumerate(available_models) if model.display_name == DEFAULT_MODEL][0])

    hasMovie = hasMovieFunction(selected_model)
    hasImage = hasImageFunction(selected_model)
    hasAudio = hasAudioFunction(selected_model)

    # max_tokens
    max_tokens_value = st.sidebar.slider(
        "ãƒˆãƒ¼ã‚¯ãƒ³æ•°ä¸Šé™",
        min_value=1,
        max_value=getMaxToken(selected_model),
        value=int(getMaxToken(selected_model)*0.5),
        step=1,
        key="max_tokens_value",
        help="å¿œç­”ã¨ã—ã¦ç”Ÿæˆã•ã‚Œã‚‹ãƒˆãƒ¼ã‚¯ãƒ³ã®æœ€å¤§å€¤ã‚’è¨­å®šã—ã¾ã™ã€‚"
    )
    # temperature
    temperature = st.sidebar.slider(
        "å‰µé€ æ€§",
        min_value=0.0,
        max_value=2.0,
        value=0.7,
        step=0.01,
        key="temperature",
        help="å¿œç­”ã®ç‹¬å‰µæ€§ã‚„å‰µé€ æ€§ã‚’è¨­å®šã—ã¾ã™ã€‚"
    )

    # éå»å±¥æ­´æ§‹ç¯‰
    # ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®å…¨ã‚»ãƒƒã‚·ãƒ§ãƒ³IDã‚’å–å¾—
    all_session_ids: list = db.get_user_session_ids(oid)
    # æ–°ã—ã„ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚’é–‹å§‹ã™ã‚‹ãŸã‚ã®ã‚ªãƒ—ã‚·ãƒ§ãƒ³ã‚’è¿½åŠ 
    NEWCHAT = "æ–°ã—ã„ãƒãƒ£ãƒƒãƒˆã‚’é–‹å§‹"
    # å…¨ã‚»ãƒƒã‚·ãƒ§ãƒ³è¿½åŠ 
    options = []
    options.append( ["-1", NEWCHAT, NEWCHAT] )
    for item in all_session_ids :
        session_id = item[0]
        jst_timestamp = parseDateTime(item[1])
        title = item[2]
        options.append([session_id,jst_timestamp,title])

    # ã‚µã‚¤ãƒ‰ãƒãƒ¼ã§ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚’é¸æŠ
    selected_session_option = st.sidebar.selectbox(
        "éå»ãƒãƒ£ãƒƒãƒˆã‚’é¸æŠ", 
        options,
        index=0,
        format_func = lambda item: f"{item[2]}",
        key="session_select_box"
    )
    session_id = selected_session_option[0]
    message_timestamp = selected_session_option[1]
    title = selected_session_option[2]

    print(f"{selected_model.display_name}:{selected_model.vendor},[{session_id}:{message_timestamp}:{title}],{st.session_state.current_chat_session_id}")

    # æ–°ã—ã„ã‚»ãƒƒã‚·ãƒ§ãƒ³IDãŒæ—¢å­˜ã®ã‚‚ã®ã¨ç•°ãªã‚‹å ´åˆã®ã¿ãƒªã‚»ãƒƒãƒˆ
    if session_id == "-1":
        if st.session_state.messages_loaded_for_session is None and st.session_state.current_chat_session_id is not None:
            #æ–°è¦ã§ç¶™ç¶šä¸­
            st.session_state.messages = db.load_chat_history_for_session(oid, st.session_state.current_chat_session_id)
        else :
            st.session_state.current_chat_session_id = generate_unique_session_id()
            st.session_state.messages = []
            st.session_state.messages_loaded_for_session = None
    else:
        print(f"å±¥æ­´ãƒ­ãƒ¼ãƒ‰ {session_id}")
        # é¸æŠã•ã‚ŒãŸæ—¢å­˜ã®ã‚»ãƒƒã‚·ãƒ§ãƒ³IDã‚’ãƒ­ãƒ¼ãƒ‰
        if st.session_state.current_chat_session_id != session_id:
            st.session_state.current_chat_session_id = session_id
            st.session_state.messages = db.load_chat_history_for_session(oid, st.session_state.current_chat_session_id)
            st.session_state.messages_loaded_for_session = session_id

    # ã‚»ãƒƒã‚·ãƒ§ãƒ³ã®ãƒªã‚»ãƒƒãƒˆãƒœã‚¿ãƒ³
    if st.session_state.messages_loaded_for_session is None and st.session_state.current_chat_session_id is not None:
        if st.sidebar.button("ãƒªã‚»ãƒƒãƒˆ"):
            st.session_state.current_chat_session_id = None
            st.session_state.messages = []
            st.session_state.messages_loaded_for_session = None
            st.rerun()

    # é¸æŠã•ã‚ŒãŸã‚»ãƒƒã‚·ãƒ§ãƒ³å±¥æ­´ã‚’å‰Šé™¤
    if session_id != "-1":
        if st.sidebar.button("å‰Šé™¤"):
            db.delete_user_session(oid, st.session_state.current_chat_session_id)
            st.session_state.current_chat_session_id = None
            st.session_state.messages = []
            st.session_state.messages_loaded_for_session = None
            st.rerun()

        # æ‹¡å¼µã‚¨ã‚­ã‚¹ãƒãƒ¼ãƒˆæ©Ÿèƒ½
        st.sidebar.subheader("ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ")
        
        # ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆå½¢å¼é¸æŠ
        export_format = st.sidebar.selectbox(
            "å½¢å¼é¸æŠ",
            ["JSON", "Markdown", "ãƒ†ã‚­ã‚¹ãƒˆ"],
            key="export_format"
        )
        
        # å˜ä¸€ã‚»ãƒƒã‚·ãƒ§ãƒ³ã®ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ
        if st.sidebar.button("ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆæº–å‚™"):
            chat_history = db.load_chat_history_for_session(oid, st.session_state.current_chat_session_id)
            
            if export_format == "ãƒ†ã‚­ã‚¹ãƒˆ":
                content = export_as_text(chat_history, st.session_state.current_chat_session_id, title)
                filename = f"chat_{st.session_state.current_chat_session_id}.txt"
                mime_type = "text/plain"
            elif export_format == "JSON":
                content = export_as_json(chat_history, st.session_state.current_chat_session_id, title)
                filename = f"chat_{st.session_state.current_chat_session_id}.json"
                mime_type = "application/json"
            elif export_format == "Markdown":
                content = export_as_markdown(chat_history, st.session_state.current_chat_session_id, title)
                filename = f"chat_{st.session_state.current_chat_session_id}.md"
                mime_type = "text/markdown"
            
            st.sidebar.download_button(
                label=f"{export_format}å½¢å¼ã§ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
                data=content,
                file_name=filename,
                mime=mime_type
            )
    else :
        st.sidebar.subheader("ã‚¤ãƒ³ãƒãƒ¼ãƒˆ")

        # ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ€ãƒ¼
        uploaded_file = st.sidebar.file_uploader(
            "JSONãƒ•ã‚¡ã‚¤ãƒ«ã‚’é¸æŠ",
            type=['json'],
            help="ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆã—ãŸJSONãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„"
        )

        if uploaded_file is not None:
            # ãƒ•ã‚¡ã‚¤ãƒ«å†…å®¹ã‚’èª­ã¿è¾¼ã¿
            json_content = uploaded_file.read().decode('utf-8')
            
            # ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼è¡¨ç¤º
            with st.sidebar.expander("ãƒ•ã‚¡ã‚¤ãƒ«å†…å®¹ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼"):
                try:
                    preview_data = json.loads(json_content)
                    st.write(f"**ã‚¿ã‚¤ãƒˆãƒ«:** {preview_data.get('title', 'N/A')}")
                    st.write(f"**ã‚»ãƒƒã‚·ãƒ§ãƒ³ID:** {preview_data.get('session_id', 'N/A')}")
                    st.write(f"**ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸æ•°:** {len(preview_data.get('messages', []))}")
                    
                    # å½¢å¼æ¤œè¨¼
                    is_valid, validation_message = validate_json_format(json_content)
                    if is_valid:
                        st.success(validation_message)
                    else:
                        st.error(validation_message)
                        
                except Exception as e:
                    st.error(f"ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ã‚¨ãƒ©ãƒ¼: {str(e)}")
            
            # ã‚¤ãƒ³ãƒãƒ¼ãƒˆãƒœã‚¿ãƒ³
            if st.sidebar.button("ã‚¤ãƒ³ãƒãƒ¼ãƒˆå®Ÿè¡Œ", type="primary"):
                with st.spinner("ã‚¤ãƒ³ãƒãƒ¼ãƒˆä¸­..."):
                    success, message = import_from_json(json_content, oid)
                    
                    if success:
                        st.sidebar.success(message)
                        # ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã‚’ãƒªã‚»ãƒƒãƒˆã—ã¦æ–°ã—ã„ãƒãƒ£ãƒƒãƒˆä¸€è¦§ã‚’è¡¨ç¤º
                        time.sleep(1)  # ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒæˆåŠŸãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’è¦‹ã‚‹æ™‚é–“ã‚’ä¸ãˆã‚‹
                        st.rerun()
                    else:
                        st.sidebar.error(message)


    # ãƒãƒ£ãƒƒãƒˆå±¥æ­´è¡¨ç¤º
    for message in st.session_state.messages:
        role = "assistant" if message.role == oci.generative_ai_inference.models.Message.ROLE_ASSISTANT else "user"
        
        with st.chat_message(role):
            for content in message.content:
                if content.type == oci.generative_ai_inference.models.TextContent.TYPE_TEXT:
                    if role == "assistant" :
                        st.markdown(content.text)
                    else:
                        st.text(content.text)
                if content.type == oci.generative_ai_inference.models.ImageContent.TYPE_IMAGE:
                    base64image = content.image_url.url.split('base64,')[1]
                    st.image(base64.b64decode(base64image))

    # ãƒãƒ£ãƒƒãƒˆ å…¥åŠ›å¾…ã¡
    prompt = None
    promptattach = None
    if hasMovie == True or hasImage == True or hasAudio == True:
        MEDIA_FORMAT= []
        if(hasMovie ) :
            MEDIA_FORMAT = MEDIA_FORMAT + ["mp4", "mpeg", "mov", "avi", "flv", "mpg", "webm", "wmv", "3gp"]
        if(hasImage ) :
            MEDIA_FORMAT = MEDIA_FORMAT + ["png", "jpeg", "jpg"]
        if(hasAudio ) :
            MEDIA_FORMAT = MEDIA_FORMAT + ["wav", "mp3", "aiff", "aac", "ogg", "flac"]
            
        promptattach = st.chat_input("ã“ã“ã«ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„...",accept_file="multiple", file_type=MEDIA_FORMAT)
        if promptattach is not None:
            prompt = promptattach.text
    else:
        prompt = st.chat_input("ã“ã“ã«ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„...")

    if prompt is not None:

        with st.chat_message("user"):
            st.text(prompt)

            if (hasMovie == True or hasImage == True or hasAudio == True) and promptattach is not None and len(promptattach.files) > 0:
                # ãƒ¡ãƒ‡ã‚£ã‚¢ãƒ•ã‚¡ã‚¤ãƒ«
                for file in promptattach.files:
                    print(f"{file.name},{file.type}")
                    if file.type.startswith("image/"):
                        st.image(file)
                    elif file.type.startswith("video/"):
                        None
                    elif file.type.startswith("audio/"):
                        None

        with st.chat_message("assistant"):
            with st.spinner("æ€è€ƒä¸­..."):

                wrap_prompt = prompt 

                chat_request = None
                if selected_model.vendor == 'cohere':

                    #éå»å±¥æ­´ä½œæˆ
                    #cohereç”¨
                    chat_history = []
                    for message in st.session_state.messages:
                        talken = message.content[0].text
                        if message.role == oci.generative_ai_inference.models.Message.ROLE_USER:
                            chat_history.append({"role": "USER", "message": talken})
                        elif message.role == oci.generative_ai_inference.models.Message.ROLE_ASSISTANT:
                            chat_history.append({"role": "CHATBOT", "message": talken})

                    #cohereç”¨
                    chat_request = CohereChatRequest(
                        api_format= oci.generative_ai_inference.models.BaseChatRequest.API_FORMAT_COHERE,
                        message=wrap_prompt + "\n" + "å‡ºåŠ›å½¢å¼:markdown",
                        chat_history=chat_history if chat_history else None,
                        max_tokens=max_tokens_value,
                        temperature=temperature,
                        is_echo=True,
                        is_stream=False
                    )
                else:

                    #æ±ç”¨
                    chat_history = []
                    for message in st.session_state.messages:
                        # ç”»åƒã¯ã€1å€‹ã¾ã§ã®ã‚ˆã†ã 
                        msg = Message()
                        msg.role = message.role
                        reqcnts = []
                        for cnt in message.content:
                            if cnt.type == ImageContent.TYPE_TEXT:
                                reqcnts.append(cnt)
                        msg.content = reqcnts

                        chat_history.append(msg)

                    #æ–°è¦ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸
                    contents = []
                    txtcontent = TextContent()
                    txtcontent.type = oci.generative_ai_inference.models.TextContent.TYPE_TEXT
                    txtcontent.text = wrap_prompt
                    contents.append(txtcontent)

                    # ç”»åƒæœ‰
                    if hasImage == True and promptattach is not None and len(promptattach.files) > 0:
                        # ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«
                        for file in promptattach.files:
                            mime_type = file.type
                            if mime_type.startswith("image/"):
                                imgcontent = ImageContent()
                                imgcontent.type = ImageContent.TYPE_IMAGE
                                base64_image = base64.b64encode(file.getvalue()).decode("utf-8")
                                imgcontent.image_url = ImageUrl( url = f"data:{file.type};base64,"+base64_image )
                                contents.append(imgcontent)
                            elif mime_type.startswith("video/"):
                                videocontent = VideoContent()
                                base64_image = base64.b64encode(file.getvalue()).decode("utf-8")
                                videocontent.video_url = VideoUrl( url = f"data:{file.type};base64,"+base64_image )
                                contents.append(videocontent)
                            elif mime_type.startswith("audio/"):
                                audiocontent = AudioContent()
                                base64_image = base64.b64encode(file.getvalue()).decode("utf-8")
                                audiocontent.audio_url = AudioUrl( url = f"data:{file.type};base64,"+base64_image )
                                contents.append(audiocontent)

                    message = Message()
                    message.role = oci.generative_ai_inference.models.Message.ROLE_USER
                    message.content = contents

                    chat_history.append(message)

                    chat_final = []
                    for msg in chat_history:
                        chat_final.append(msg)

                    # ã‚·ã‚¹ãƒ†ãƒ ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ è¿½åŠ 
                    sysmessage = Message()
                    sysmessage.role = oci.generative_ai_inference.models.Message.ROLE_SYSTEM
                    syscontents = []
                    txtcontent = TextContent()
                    txtcontent.type = oci.generative_ai_inference.models.TextContent.TYPE_TEXT
                    txtcontent.text = "å‡ºåŠ›å½¢å¼:markdown"
                    syscontents.append(txtcontent)

                    sysmessage.content = syscontents
                    chat_final.append(sysmessage)

                    chat_request = GenericChatRequest(
                        api_format=oci.generative_ai_inference.models.BaseChatRequest.API_FORMAT_GENERIC,
                        messages=chat_final,
                        max_tokens=max_tokens_value,
                        temperature=temperature
                    )

                #æ–°è¦ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ ãƒãƒ£ãƒƒãƒˆå±¥æ­´è¿½åŠ 
                contents = []
                txtcontent = TextContent()
                txtcontent.type = oci.generative_ai_inference.models.TextContent.TYPE_TEXT
                txtcontent.text = prompt
                contents.append(txtcontent)

                # ç”»åƒæœ‰
                if (hasMovie == True or hasImage == True or hasAudio == True) and promptattach is not None and len(promptattach.files) > 0:
                    # ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«
                    for file in promptattach.files:
                        mime_type = file.type
                        if mime_type.startswith("image/"):
                            imgcontent = ImageContent()
                            imgcontent.type = ImageContent.TYPE_IMAGE
                            base64_image = base64.b64encode(file.getvalue()).decode("utf-8")
                            imgcontent.image_url = ImageUrl( url = f"data:{file.type};base64,"+base64_image )
                            contents.append(imgcontent)
                        elif mime_type.startswith("video/"):
                            videocontent = VideoContent()
                            videocontent.type = videocontent.TYPE_IMAGE
                            base64_image = base64.b64encode(file.getvalue()).decode("utf-8")
                            videocontent.video_url = VideoUrl( url = f"data:{file.type};base64,"+base64_image )
                            contents.append(videocontent)
                        elif mime_type.startswith("audio/"):
                            audiocontent = AudioContent()
                            audiocontent.type = AudioContent.TYPE_IMAGE
                            base64_image = base64.b64encode(file.getvalue()).decode("utf-8")
                            audiocontent.audio_url = AudioUrl( url = f"data:{file.type};base64,"+base64_image )
                            contents.append(audiocontent)

                newmessage = Message()
                newmessage.role = oci.generative_ai_inference.models.Message.ROLE_USER
                newmessage.content = contents

                st.session_state.messages.append(newmessage)
                # DB ãƒãƒ£ãƒƒãƒˆå±¥æ­´è¿½åŠ 
                jstnow = datetime.datetime.now(jst_timezone).strftime('%Y-%m-%d %Hæ™‚')
                title = f"{jstnow} {prompt[:20]}"
                db.save_chat_message(oid, st.session_state.current_chat_session_id, "USER", prompt, title)

                # ãƒãƒ£ãƒƒãƒˆé€ä¿¡å‡¦ç†
                serving_mode = OnDemandServingMode(model_id=selected_model.id)
                chat_details = ChatDetails(
                    compartment_id=COMPARTMENT_ID,
                    chat_request=chat_request,
                    serving_mode=serving_mode
                )
                response:oci.response.Response = client.chat(chat_details)
                result:oci.generative_ai_inference.models.ChatResult = response.data

                bot_reply = ""
                if selected_model.vendor == 'cohere':
                    #cohereç”¨
                    bot_reply = result.chat_response.text

                    if bot_reply:
                        # å¿œç­” ãƒãƒ£ãƒƒãƒˆå±¥æ­´è¿½åŠ 
                        contents = []
                        txtcontent = TextContent()
                        txtcontent.type = oci.generative_ai_inference.models.TextContent.TYPE_TEXT
                        txtcontent.text = bot_reply
                        contents.append(txtcontent)

                        message = Message()
                        message.role = oci.generative_ai_inference.models.Message.ROLE_ASSISTANT
                        message.content = contents

                        st.session_state.messages.append(message)

                        # DB ãƒãƒ£ãƒƒãƒˆå±¥æ­´è¿½åŠ 
                        db.save_chat_message(oid, st.session_state.current_chat_session_id, "CHATBOT", bot_reply, title)
                        # å‡ºåŠ›
                        st.markdown(bot_reply)

                else:
                    #æ±ç”¨
                    generic_response:oci.generative_ai_inference.models.generic_chat_response.GenericChatResponse = result.chat_response

                    for chatchoice in generic_response.choices:

                        msg:oci.generative_ai_inference.models.Message = chatchoice.message

                        for cnt in msg.content:
                            if isinstance(cnt,oci.generative_ai_inference.models.TextContent):
                                txt:oci.generative_ai_inference.models.TextContent = cnt
                                bot_reply = txt.text
                            elif isinstance(cnt,oci.generative_ai_inference.models.ImageContent):
                                img:oci.generative_ai_inference.models.ImageContent = cnt
                                bot_reply = img.image_url
                            elif isinstance(cnt,oci.generative_ai_inference.models.AudioContent):
                                audio:oci.generative_ai_inference.models.AudioContent = cnt
                                bot_reply = audio.audio_url
                            elif isinstance(cnt,oci.generative_ai_inference.models.VideoContent):
                                video:oci.generative_ai_inference.models.VideoContent = cnt
                                bot_reply = video.video_url

                        if bot_reply:
                            # å¿œç­” ãƒãƒ£ãƒƒãƒˆå±¥æ­´è¿½åŠ 
                            contents = []
                            txtcontent = TextContent()
                            txtcontent.type = oci.generative_ai_inference.models.TextContent.TYPE_TEXT
                            txtcontent.text = bot_reply
                            contents.append(txtcontent)

                            message = Message()
                            message.role = oci.generative_ai_inference.models.Message.ROLE_ASSISTANT
                            message.content = contents

                            st.session_state.messages.append(message)

                            # DB ãƒãƒ£ãƒƒãƒˆå±¥æ­´è¿½åŠ 
                            db.save_chat_message(oid, st.session_state.current_chat_session_id, "CHATBOT", bot_reply, title)
                            # å‡ºåŠ›
                            st.markdown(bot_reply)
